{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "The purpose of this notebook is to get the data from kaggle.\n",
    "Since the dataset is about 200 000 images, but we only need a fraction of that, this notebook will also be responsible for removing unnecessary data and structuring the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Dataset is already split up into train, test and validation, however we merge all into one and split our data ourselves at a later stage_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes no inputs, outputs a folder \"dataset\" with 2 subfolders \"male\" and \"female\" containing equal amounts of images totaling to specified amount SUBSET_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Vars\n",
    "DATASET = 'ashishjangra27/gender-recognition-200k-images-celeba'\n",
    "SUBSET_IMGS = 3000\n",
    "LIVE_PREDICTION_SUBSET = 60\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "LIVE_PREDICTION_DIR = os.path.join(ROOT_DIR, 'assets', 'live_prediction_images')\n",
    "\n",
    "# Set kaggle.json path\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/linuselvius/Documents/CI/genderpredictor/genderpredictor/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "\n",
    "# Authenticate\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "# Download dataset\n",
    "kaggle.api.dataset_download_files(DATASET, path=ROOT_DIR, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(ROOT_DIR, 'Dataset')  # Dataset folder path\n",
    "dirs = [dir for dir in os.listdir(dataset_dir)]  # ['Train', 'Test', 'Validation']\n",
    "male_dirs = []\n",
    "female_dirs = []\n",
    "\n",
    "# Create lists of all directory paths\n",
    "for dir in dirs:\n",
    "    current_dirs = os.listdir(os.path.join(dataset_dir, dir))\n",
    "    for child in current_dirs:\n",
    "        if child == 'Male':\n",
    "            male_dirs.append(os.path.join(dataset_dir, dir, child))\n",
    "        elif child == 'Female':\n",
    "            female_dirs.append(os.path.join(dataset_dir, dir, child))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/linuselvius/Documents/CI/genderpredictor/genderpredictor/Dataset/Test/Male',\n",
       " '/Users/linuselvius/Documents/CI/genderpredictor/genderpredictor/Dataset/Train/Male',\n",
       " '/Users/linuselvius/Documents/CI/genderpredictor/genderpredictor/Dataset/Validation/Male']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new directories\n",
    "main_dir = 'temp_dataset'\n",
    "dirs = ['train', 'test', 'val']\n",
    "\n",
    "os.mkdir(os.path.join(ROOT_DIR, main_dir))\n",
    "\n",
    "# Create train, test, val in new temp_dataset\n",
    "for dir in dirs:\n",
    "    os.mkdir(os.path.join(ROOT_DIR, main_dir, dir))\n",
    "\n",
    "# Create male, female dirs in each new dir\n",
    "for dir in dirs:\n",
    "    os.mkdir(os.path.join(ROOT_DIR, main_dir, dir, 'male'))\n",
    "    os.mkdir(os.path.join(ROOT_DIR, main_dir, dir, 'female'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all filepaths, create train, test, val dataframes\n",
    "male_files = []\n",
    "female_files = []\n",
    "male_labels = []\n",
    "female_labels = []\n",
    "\n",
    "# Loop through directories and append filepaths\n",
    "for male_dir, female_dir in zip(male_dirs, female_dirs):\n",
    "    for male_file, female_file in zip(os.listdir(male_dir), os.listdir(female_dir)):\n",
    "        male_files.append(male_file)\n",
    "        female_files.append(female_file)\n",
    "        male_labels.append(1)\n",
    "        female_labels.append(0)\n",
    "\n",
    "# Create dataframe\n",
    "data = {'file': male_files + female_files, 'gender': male_labels + female_labels}\n",
    "df = pd.DataFrame(data = data)\n",
    "\n",
    "# Keep only SUBSET_IMGS / 2 images of each gender\n",
    "df_male = df.head(int(SUBSET_IMGS / 2))\n",
    "df_female = df.tail(int(SUBSET_IMGS / 2))\n",
    "df = pd.concat([df_male, df_female], axis=0)\n",
    "\n",
    "# Shuffle dataframe\n",
    "df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Split dataframe into train and temp\n",
    "df_train, df_temp = train_test_split(df, test_size=1 - train_ratio, random_state=42)\n",
    "# Split temp dataframe into test and val\n",
    "df_val, df_test = train_test_split(df_temp, test_size=test_ratio / (test_ratio + val_ratio), random_state=42)\n",
    "\n",
    "# Save dataframes to csv\n",
    "df_train.to_csv(os.path.join(ROOT_DIR, main_dir, 'train', 'train.csv'), index=False)\n",
    "df_test.to_csv(os.path.join(ROOT_DIR, main_dir, 'test', 'test.csv'), index=False)\n",
    "df_val.to_csv(os.path.join(ROOT_DIR, main_dir, 'val', 'val.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/linuselvius/Documents/CI/genderpredictor/genderpredictor/assets/live_prediction_images/male'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39m==\u001b[39m subset_size_live_prediction:\n\u001b[1;32m     26\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m shutil\u001b[39m.\u001b[39;49mcopy2(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(male_dir, male_file), os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(ROOT_DIR, LIVE_PREDICTION_DIR, \u001b[39m'\u001b[39;49m\u001b[39mmale\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     28\u001b[0m shutil\u001b[39m.\u001b[39mcopy2(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(female_dir, female_file), os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(ROOT_DIR, LIVE_PREDICTION_DIR, \u001b[39m'\u001b[39m\u001b[39mfemale\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     29\u001b[0m index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(dst):\n\u001b[1;32m    433\u001b[0m     dst \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dst, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(src))\n\u001b[0;32m--> 434\u001b[0m copyfile(src, dst, follow_symlinks\u001b[39m=\u001b[39;49mfollow_symlinks)\n\u001b[1;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[39m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    436\u001b[0m \u001b[39mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(src, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(dst, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m             \u001b[39m# macOS\u001b[39;00m\n\u001b[1;32m    258\u001b[0m             \u001b[39mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[1;32m    259\u001b[0m                 \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/linuselvius/Documents/CI/genderpredictor/genderpredictor/assets/live_prediction_images/male'"
     ]
    }
   ],
   "source": [
    "# Copy number of files SUBSET_IMGS to new dataset directories and number of files LIVE_PREDICTION_SUBSET to directory\n",
    "for male_dir, female_dir in zip(male_dirs, female_dirs):\n",
    "    index = 0\n",
    "    for male_file, female_file in zip(os.listdir(male_dir), os.listdir(female_dir)):\n",
    "        # Copy to appropriate folder\n",
    "        if df_train['file'].isin([male_file]).any():\n",
    "            shutil.copy2(os.path.join(male_dir, male_file), os.path.join(ROOT_DIR, main_dir, 'train', 'male'))\n",
    "        elif df_train['file'].isin([female_file]).any():\n",
    "            shutil.copy2(os.path.join(female_dir, female_file), os.path.join(ROOT_DIR, main_dir, 'train', 'female'))\n",
    "        elif df_test['file'].isin([male_file]).any():\n",
    "            shutil.copy2(os.path.join(male_dir, male_file), os.path.join(ROOT_DIR, main_dir, 'test', 'male'))\n",
    "        elif df_test['file'].isin([female_file]).any():\n",
    "            shutil.copy2(os.path.join(female_dir, female_file), os.path.join(ROOT_DIR, main_dir, 'test', 'female'))\n",
    "        elif df_val['file'].isin([male_file]).any():\n",
    "            shutil.copy2(os.path.join(male_dir, male_file), os.path.join(ROOT_DIR, main_dir, 'val', 'male'))\n",
    "        elif df_val['file'].isin([female_file]).any():\n",
    "            shutil.copy2(os.path.join(female_dir, female_file), os.path.join(ROOT_DIR, main_dir, 'val', 'female'))\n",
    "        index += 1\n",
    "\n",
    "subset_size_live_prediction = round(LIVE_PREDICTION_SUBSET / len(male_dirs + female_dirs))  \n",
    "# Copy live prediction images\n",
    "for male_dir, female_dir in zip(male_dirs, female_dirs):\n",
    "    index = 0\n",
    "    for male_file, female_file in zip(os.listdir(male_dir)[int(SUBSET_IMGS/2)+1:], os.listdir(female_dir)[int(SUBSET_IMGS/2)+1:]):\n",
    "        if index == subset_size_live_prediction:\n",
    "            break\n",
    "        shutil.copy2(os.path.join(male_dir, male_file), os.path.join(ROOT_DIR, LIVE_PREDICTION_DIR, 'male'))\n",
    "        shutil.copy2(os.path.join(female_dir, female_file), os.path.join(ROOT_DIR, LIVE_PREDICTION_DIR, 'female'))\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove original dataset\n",
    "\n",
    "shutil.rmtree(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male dir in train: 895 images\n",
      "Male dir in test: 310 images\n",
      "Male dir in val: 295 images\n",
      "Female dir in train: 905 images\n",
      "Female dir in test: 290 images\n",
      "Female dir in val: 305 images\n",
      "Total in dataset: 3000 images\n",
      "Male dir in live prediction folder: 0 images\n",
      "Female dir in live prediction folder: 0 images\n",
      "Total in live prediction folder: 0 images\n"
     ]
    }
   ],
   "source": [
    "# Check size of new data\n",
    "\n",
    "male_size_train = len(os.listdir(os.path.join(ROOT_DIR, main_dir, 'train', 'male')))\n",
    "female_size_train = len(os.listdir(os.path.join(ROOT_DIR, main_dir, 'train', 'female')))\n",
    "male_size_test = len(os.listdir(os.path.join(ROOT_DIR, main_dir, 'test', 'male')))\n",
    "female_size_test = len(os.listdir(os.path.join(ROOT_DIR, main_dir, 'test', 'female')))\n",
    "male_size_val = len(os.listdir(os.path.join(ROOT_DIR, main_dir, 'val', 'male')))\n",
    "female_size_val = len(os.listdir(os.path.join(ROOT_DIR, main_dir, 'val', 'female')))\n",
    "live_prediction_male_size = len(os.listdir(os.path.join(ROOT_DIR, LIVE_PREDICTION_DIR, 'male')))\n",
    "live_prediction_female_size = len(os.listdir(os.path.join(ROOT_DIR, LIVE_PREDICTION_DIR, 'female')))\n",
    "\n",
    "print(f'Male dir in train: {male_size_train} images')\n",
    "print(f'Male dir in test: {male_size_test} images')\n",
    "print(f'Male dir in val: {male_size_val} images')\n",
    "print(f'Female dir in train: {female_size_train} images')\n",
    "print(f'Female dir in test: {female_size_test} images')\n",
    "print(f'Female dir in val: {female_size_val} images')\n",
    "print(f'Total in dataset: {male_size_train + male_size_test + male_size_val + female_size_train + female_size_test + female_size_val} images')\n",
    "\n",
    "print(f'Male dir in live prediction folder: {live_prediction_male_size} images')\n",
    "print(f'Female dir in live prediction folder: {live_prediction_female_size} images')\n",
    "print(f'Total in live prediction folder: {live_prediction_male_size + live_prediction_female_size} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename temp_dataset to dataset\n",
    "os.rename(os.path.join(ROOT_DIR, main_dir), os.path.join(ROOT_DIR, 'dataset'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
