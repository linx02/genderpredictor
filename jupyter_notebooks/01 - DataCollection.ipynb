{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "The purpose of this notebook is to get the data from kaggle.\n",
    "Since the dataset is about 200 000 images, but we only need a fraction of that, this notebook will also be responsible for removing unnecessary data and structuring the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Dataset is already split up into train, test and validation, however we merge all into one and split our data ourselves at a later stage_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Vars\n",
    "DATASET = 'ashwingupta3012/male-and-female-faces-dataset/data'\n",
    "SUBSET_IMGS = 3000\n",
    "LIVE_PREDICTION_SUBSET = 60\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "LIVE_PREDICTION_DIR = os.path.join(ROOT_DIR, 'assets', 'live_prediction_images')\n",
    "\n",
    "# Set kaggle.json path\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /workspace/genderpredictor/kaggle.json'\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /workspace/genderpredictor/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "\n",
    "# Authenticate\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "# Download dataset\n",
    "kaggle.api.dataset_download_files(DATASET, path=ROOT_DIR, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(ROOT_DIR, 'Dataset')  # Dataset folder path\n",
    "dirs = [dir for dir in os.listdir(dataset_dir)]  # ['Train', 'Test', 'Validation']\n",
    "male_dirs = []\n",
    "female_dirs = []\n",
    "\n",
    "# Create lists of all directory paths\n",
    "for dir in dirs:\n",
    "    current_dirs = os.listdir(os.path.join(dataset_dir, dir))\n",
    "    for child in current_dirs:\n",
    "        if child == 'Male':\n",
    "            male_dirs.append(os.path.join(dataset_dir, dir, child))\n",
    "        elif child == 'Female':\n",
    "            female_dirs.append(os.path.join(dataset_dir, dir, child))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace/genderpredictor/Dataset/Test/Male',\n",
       " '/workspace/genderpredictor/Dataset/Train/Male',\n",
       " '/workspace/genderpredictor/Dataset/Validation/Male']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new directories\n",
    "main_dir = 'temp_dataset'\n",
    "dirs = ['train', 'test', 'val']\n",
    "\n",
    "os.mkdir(os.path.join(ROOT_DIR, main_dir))\n",
    "\n",
    "# Create train, test, val in new temp_dataset\n",
    "for dir in dirs:\n",
    "    os.mkdir(os.path.join(ROOT_DIR, main_dir, dir))\n",
    "\n",
    "# Create male, female dirs in each new dir\n",
    "for dir in dirs:\n",
    "    os.mkdir(os.path.join(ROOT_DIR, main_dir, dir, 'male'))\n",
    "    os.mkdir(os.path.join(ROOT_DIR, main_dir, dir, 'female'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all filepaths, create train, test, val dataframes\n",
    "male_files = []\n",
    "female_files = []\n",
    "male_labels = []\n",
    "female_labels = []\n",
    "\n",
    "# Loop through directories and append filepaths\n",
    "for male_dir, female_dir in zip(male_dirs, female_dirs):\n",
    "    for male_file, female_file in zip(os.listdir(male_dir), os.listdir(female_dir)):\n",
    "        male_files.append(male_file)\n",
    "        female_files.append(female_file)\n",
    "        male_labels.append(1)\n",
    "        female_labels.append(0)\n",
    "\n",
    "# Create dataframe\n",
    "data = {'file': male_files + female_files, 'gender': male_labels + female_labels}\n",
    "df = pd.DataFrame(data = data)\n",
    "\n",
    "# Keep only SUBSET_IMGS / 2 images of each gender\n",
    "df_male = df.head(int(SUBSET_IMGS / 2))\n",
    "df_female = df.tail(int(SUBSET_IMGS / 2))\n",
    "df = pd.concat([df_male, df_female], axis=0)\n",
    "\n",
    "# Shuffle dataframe\n",
    "df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Split dataframe into train and temp\n",
    "df_train, df_temp = train_test_split(df, test_size=1 - train_ratio, random_state=42)\n",
    "# Split temp dataframe into test and val\n",
    "df_val, df_test = train_test_split(df_temp, test_size=test_ratio / (test_ratio + val_ratio), random_state=42)\n",
    "\n",
    "# Save dataframes to csv\n",
    "df_train.to_csv(os.path.join(ROOT_DIR, main_dir, 'train', 'train.csv'), index=False)\n",
    "df_test.to_csv(os.path.join(ROOT_DIR, main_dir, 'test', 'test.csv'), index=False)\n",
    "df_val.to_csv(os.path.join(ROOT_DIR, main_dir, 'val', 'val.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy number of files SUBSET_IMGS to new dataset directories and number of files LIVE_PREDICTION_SUBSET to directory\n",
    "for male_dir, female_dir in zip(male_dirs, female_dirs):\n",
    "    index = 0\n",
    "    for male_file, female_file in zip(os.listdir(male_dir), os.listdir(female_dir)):\n",
    "        # Copy to appropriate folder\n",
    "        if df_train['file'].isin([male_file]).any():\n",
    "            shutil.copy2(os.path.join(male_dir, male_file), os.path.join(ROOT_DIR, main_dir, 'train', 'male'))\n",
    "        elif df_train['file'].isin([female_file]).any():\n",
    "            shutil.copy2(os.path.join(female_dir, female_file), os.path.join(ROOT_DIR, main_dir, 'train', 'female'))\n",
    "        elif df_test['file'].isin([male_file]).any():\n",
    "            shutil.copy2(os.path.join(male_dir, male_file), os.path.join(ROOT_DIR, main_dir, 'test', 'male'))\n",
    "        elif df_test['file'].isin([female_file]).any():\n",
    "            shutil.copy2(os.path.join(female_dir, female_file), os.path.join(ROOT_DIR, main_dir, 'test', 'female'))\n",
    "        elif df_val['file'].isin([male_file]).any():\n",
    "            shutil.copy2(os.path.join(male_dir, male_file), os.path.join(ROOT_DIR, main_dir, 'val', 'male'))\n",
    "        elif df_val['file'].isin([female_file]).any():\n",
    "            shutil.copy2(os.path.join(female_dir, female_file), os.path.join(ROOT_DIR, main_dir, 'val', 'female'))\n",
    "        index += 1\n",
    "\n",
    "subset_size_live_prediction = round(LIVE_PREDICTION_SUBSET / len(male_dirs + female_dirs))  \n",
    "# Copy live prediction images\n",
    "for male_dir, female_dir in zip(male_dirs, female_dirs):\n",
    "    index = 0\n",
    "    for male_file, female_file in zip(os.listdir(male_dir)[int(SUBSET_IMGS/2)+1:], os.listdir(female_dir)[int(SUBSET_IMGS/2)+1:]):\n",
    "        if index == subset_size_live_prediction:\n",
    "            break\n",
    "        shutil.copy2(os.path.join(male_dir, male_file), os.path.join(ROOT_DIR, LIVE_PREDICTION_DIR, 'male'))\n",
    "        shutil.copy2(os.path.join(female_dir, female_file), os.path.join(ROOT_DIR, LIVE_PREDICTION_DIR, 'female'))\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove original dataset\n",
    "\n",
    "shutil.rmtree(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male dir in train: 895 images\n",
      "Male dir in test: 310 images\n",
      "Male dir in val: 295 images\n",
      "Female dir in train: 905 images\n",
      "Female dir in test: 290 images\n",
      "Female dir in val: 305 images\n",
      "Total in dataset: 3000 images\n",
      "Male dir in live prediction folder: 30 images\n",
      "Female dir in live prediction folder: 30 images\n",
      "Total in live prediction folder: 60 images\n"
     ]
    }
   ],
   "source": [
    "# Check size of new data\n",
    "\n",
    "male_size_train = len(os.listdir(os.path.join(ROOT_DIR, main_dir, 'train', 'male')))\n",
    "female_size_train = len(os.listdir(os.path.join(ROOT_DIR, main_dir, 'train', 'female')))\n",
    "male_size_test = len(os.listdir(os.path.join(ROOT_DIR, main_dir, 'test', 'male')))\n",
    "female_size_test = len(os.listdir(os.path.join(ROOT_DIR, main_dir, 'test', 'female')))\n",
    "male_size_val = len(os.listdir(os.path.join(ROOT_DIR, main_dir, 'val', 'male')))\n",
    "female_size_val = len(os.listdir(os.path.join(ROOT_DIR, main_dir, 'val', 'female')))\n",
    "live_prediction_male_size = len(os.listdir(os.path.join(ROOT_DIR, LIVE_PREDICTION_DIR, 'male')))\n",
    "live_prediction_female_size = len(os.listdir(os.path.join(ROOT_DIR, LIVE_PREDICTION_DIR, 'female')))\n",
    "\n",
    "print(f'Male dir in train: {male_size_train} images')\n",
    "print(f'Male dir in test: {male_size_test} images')\n",
    "print(f'Male dir in val: {male_size_val} images')\n",
    "print(f'Female dir in train: {female_size_train} images')\n",
    "print(f'Female dir in test: {female_size_test} images')\n",
    "print(f'Female dir in val: {female_size_val} images')\n",
    "print(f'Total in dataset: {male_size_train + male_size_test + male_size_val + female_size_train + female_size_test + female_size_val} images')\n",
    "\n",
    "print(f'Male dir in live prediction folder: {live_prediction_male_size} images')\n",
    "print(f'Female dir in live prediction folder: {live_prediction_female_size} images')\n",
    "print(f'Total in live prediction folder: {live_prediction_male_size + live_prediction_female_size} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename temp_dataset to dataset\n",
    "os.rename(os.path.join(ROOT_DIR, main_dir), os.path.join(ROOT_DIR, 'dataset'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
